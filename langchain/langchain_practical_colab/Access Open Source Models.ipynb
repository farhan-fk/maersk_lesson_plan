{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12214,
     "status": "ok",
     "timestamp": 1758635150008,
     "user": {
      "displayName": "Farhan Khan",
      "userId": "15469157280639804773"
     },
     "user_tz": -330
    },
    "id": "uUN202A1yh68",
    "outputId": "9a125ca1-dddd-481f-a26e-2b0d84309142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (0.31.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 622,
     "status": "ok",
     "timestamp": 1758635137579,
     "user": {
      "displayName": "Farhan Khan",
      "userId": "15469157280639804773"
     },
     "user_tz": -330
    },
    "id": "c3aba889",
    "outputId": "4cce9729-7f43-4833-b688-c881ce35159e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have."
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "# Replace \"YOUR_API_KEY_HERE\" with your actual Groq API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi, tell me who you are?\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=0.6,\n",
    "    max_completion_tokens=4096,\n",
    "    top_p=0.95,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1758635261118,
     "user": {
      "displayName": "Farhan Khan",
      "userId": "15469157280639804773"
     },
     "user_tz": -330
    },
    "id": "GRxdOO_X1D6r",
    "outputId": "a4d76654-194e-4c2a-800f-f2dbad939bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am Gemma, an AI assistant created by the Gemma team at Google DeepMind.\n",
      "\n",
      "Here's what I can tell you about myself:\n",
      "\n",
      "* **Open-weights:** My weights are publicly accessible, meaning anyone can see and use the code that makes me work. This promotes transparency and collaboration in the AI community.\n",
      "* **Text-only:** I can only communicate through text. I can read and understand your written questions and requests, and I generate my responses as text.\n",
      "* **Knowledge cutoff:** My knowledge is based on the data I was trained on, which has a cutoff point. I don't have access to real-time information or the ability to search the internet for updates.\n",
      "\n",
      "* **No tools:** I'm purely a language model. I can't interact with external tools or software.\n",
      "\n",
      "My purpose is to help people by understanding and responding to their requests in a helpful, informative, and comprehensive way. I can help with tasks like:\n",
      "\n",
      "* **Generating different creative text formats:**\n",
      "\n",
      "Poems, code, scripts, musical pieces, email, letters, etc.\n",
      "* **Answering your questions in an informative way:** Even if they are open ended, challenging, or strange.\n",
      "* **Summarizing factual topics:** Provide concise summaries of factual topics based on my training data.\n",
      "\n",
      "I am still under development, but I am learning new things every day.\n",
      "\n",
      "I am excited to see how people use me to explore the possibilities of AI!\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me about urself?\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1758635343652,
     "user": {
      "displayName": "Farhan Khan",
      "userId": "15469157280639804773"
     },
     "user_tz": -330
    },
    "id": "O5tIfxoy1Ml3",
    "outputId": "23513ed7-2111-4263-8f26-e273f87077b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-guard-4-12b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me about urself?\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOHNW5JvJW3Roh/EG5TwZYK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
